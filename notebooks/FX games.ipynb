{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# require at least Python 3.5 for async/await to work\n",
    "import sys\n",
    "ver=sys.version_info\n",
    "assert (ver[0]>=3 and ver[1]>=5)\n",
    "sys.path.append('../../quant_container/src')\n",
    "sys.path.append('../../quant-container/src')\n",
    "sys.path.append('../src')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mosaicsmartdata.core.fx import FXPricingContextGenerator\n",
    "from mosaicsmartdata.common import qc_csv_helper\n",
    "from mosaicsmartdata.core.quote import Quote\n",
    "import csv, copy\n",
    "import pickle, cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('data.pickle', 'rb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        quote_dict = pickle.load(f)\n",
    "except:\n",
    "#if True:\n",
    "    file_path ='../resources/fx/'\n",
    "    filenames = ['OIS-N156898469.csv','EUR_JPY_GBP_till_SN.csv','EUR_JPY_GBP_from_SW_till_1Y.csv']\n",
    "    quote_dict_0 = qc_csv_helper.get_ric_quotes(file_path+filenames[0])\n",
    "    print(len(quote_dict_0), quote_dict_0.keys())\n",
    "    quote_dict_1 = qc_csv_helper.get_ric_quotes(file_path+filenames[1])\n",
    "    print(len(quote_dict_1), quote_dict_1.keys())\n",
    "    quote_dict_2 = qc_csv_helper.get_ric_quotes(file_path+filenames[2])\n",
    "    print(len(quote_dict_2), quote_dict_2.keys())\n",
    "    quote_dict = dict(quote_dict_0,**quote_dict_1)\n",
    "    quote_dict = dict(quote_dict,**quote_dict_2)\n",
    "    with open('data.pickle', 'wb') as f:\n",
    "        pickle.dump(quote_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_dict['EURSN='][0].instrument.settle_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a trade\n",
    "from mosaicsmartdata.core.instrument_utils import sym_to_instrument\n",
    "from mosaicsmartdata.core.trade import Trade, FXForwardTrade\n",
    "\n",
    "#spot_quotes = [quotes for sym, quotes in quote_dict.items() if len(sym)==4]\n",
    "my_quote = quote_dict['EUR='][100]\n",
    "my_instr = sym_to_instrument()(my_quote.sym, my_quote.timestamp.date())\n",
    "my_instr.notionals = (100, -100*my_quote.bid)\n",
    "print(my_instr)\n",
    "print('*****')\n",
    "my_trade = FXForwardTrade(my_instr, \n",
    "                          trade_id = '12345',\n",
    "                        timestamp = my_quote.timestamp)\n",
    "print(my_trade)\n",
    "print('*******')\n",
    "print(my_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from aiostreams import run\n",
    "import aiostreams.operators as op\n",
    "from mosaicsmartdata.core.markout import MarkoutCalculator\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run markouts based on simple instrument ID, with no pricing context\n",
    "# logging.getLogger().setLevel('INFO')\n",
    "# logging.info('starting command line test...')\n",
    "\n",
    "# run the markout calc\n",
    "trades = [my_trade]\n",
    "quotes = quote_dict['EUR=']\n",
    "stream = op.merge_sorted([quotes[:1000], trades], lambda x: x.timestamp) \\\n",
    "            | op.flat_map_by_group(lambda x: x.sym, MarkoutCalculator([-10, 0, 10, 100]))\\\n",
    "            > print\n",
    "        \n",
    "run(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run markouts using PricingContext\n",
    "# run the markout calc\n",
    "\n",
    "quotes_eur = quote_dict['EUR=']\n",
    "quotes_jpy = quote_dict['JPY=']\n",
    "print(len(quotes_jpy),len(quotes_eur))\n",
    "quotes_all = op.merge_sorted([quotes_eur[:1000],quotes_jpy[:1000]], lambda x: x.timestamp) > []\n",
    "             #|\\op.map(lambda x: (x.sym, x.timestamp)) > \n",
    "run(quotes_all)\n",
    "\n",
    "my_quote = quotes_all.sink[100]\n",
    "my_instr_2 = sym_to_instrument()('EURJPY=', my_quote.timestamp.date())\n",
    "my_instr_2.notionals = (100, -100*124.594511) # just picked a random quote\n",
    "print(my_instr_2) \n",
    "print('*****')\n",
    "my_trade_2 = FXForwardTrade(my_instr_2, \n",
    "                          trade_id = '12346',\n",
    "                        timestamp = my_quote.timestamp)\n",
    "print(my_trade_2.timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#markouts using PricingContext\n",
    "trades = [my_trade]\n",
    "quotes_2 = quotes_all.sink\n",
    "#print([quote.sym for quote in quotes_2][:100])\n",
    "\n",
    "prices =  quotes_2 | op.map(FXPricingContextGenerator()) \n",
    "#stream = prices | op.map(lambda x: x.timestamp) > print\n",
    "stream = op.merge_sorted([trades,prices], lambda x:x.timestamp)\\\n",
    "        | op.flat_map(MarkoutCalculator([-10,0, 10, 100])) | op.map(lambda x:str(x))\\\n",
    "        > []\n",
    "run(stream)       \n",
    "\n",
    "stream.sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract just the first quote from every stream\n",
    "tiny_quote_dict = {key:[quotes[0]] for key, quotes in quote_dict.items()}\n",
    "print([(key,quotes[0].bid, quotes[0].instrument.ccy, quotes[0].instrument.tenor) for key, quotes in tiny_quote_dict.items()])\n",
    "with open('../resources/fx/data.pickle', 'wb') as f:\n",
    "        pickle.dump(tiny_quote_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "a = datetime.date(2107,1,1)\n",
    "b = datetime.date(2107,1,2)\n",
    "from mosaicsmartdata.common.quantlib.bond.fixed_bond import pydate_to_qldate\n",
    "pydate_to_qldate(b)< pydate_to_qldate(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from random import shuffle\n",
    "\n",
    "with open('../resources/fx/data.pickle', 'rb') as f:\n",
    "        tiny_quote_dict = pickle.load(f)\n",
    "\n",
    "# that one quote happens to have the wrong date\n",
    "tiny_quote_dict['USDSWOIS='][0].timestamp -= timedelta(days=1)\n",
    "tiny_quote_dict['USDSWOIS='][0].instrument.spot_settle_date -= timedelta(days=1)\n",
    "tiny_quote_dict['USDSWOIS='][0].instrument.maturity_date -= timedelta(days=1)\n",
    "\n",
    "tiny_quotes_list =[quotes for key, quotes in tiny_quote_dict.items()]\n",
    "\n",
    "#pc.extra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(tiny_quotes_list)\n",
    "\n",
    "#[print(q[0].instrument.sym, q[0].timestamp.date()) for q in tiny_quotes_list]\n",
    "stream = op.merge_sorted(tiny_quotes_list, lambda x: x.timestamp) |\\\n",
    "            op.flat_map(FXPricingContextGenerator()) > []\n",
    "run(stream)\n",
    "pc = stream.sink[-1]\n",
    "\n",
    "for sym, quote in tiny_quote_dict.items():\n",
    "    #if 'OIS' not in sym: #and 'TN' not in sym:\n",
    "            mid = quote[0].mid\n",
    "            instr = quote[0].instrument\n",
    "            est = instr.price(pc)\n",
    "            if abs(mid-est) > 1e-6:\n",
    "                print(sym, mid, est, abs(mid-est), \n",
    "                      quote[0].timestamp.date(), \n",
    "                      instr.settle_date, \n",
    "                      instr.maturity_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbpsn = [q[0] for q in tiny_quotes_list if q[0].sym == 'GBPSN=']\n",
    "print(gbpsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mosaicsmartdata.core.curve_utils import construct_OIS_curve, discounting_factor\n",
    "import datetime\n",
    "\n",
    "with open('EUR_curve.pickle', 'rb') as f:\n",
    "        EUR_df = pickle.load(f)\n",
    "print(EUR_df)\n",
    "        \n",
    "eur_curve =  construct_OIS_curve(EUR_df)\n",
    "a1 = datetime.date(2017, 6, 26)\n",
    "a2 = datetime.date(2017, 6, 27)\n",
    "b = datetime.date(2017, 6, 28)\n",
    "df1 = discounting_factor(eur_curve, a1, b)\n",
    "df2 = discounting_factor(eur_curve, a2, b)\n",
    "print(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.extra['EUR']\n",
    "for sym, quote in tiny_quote_dict.items():\n",
    "    if 'EUR' in sym:\n",
    "        print(quote[0].mid, quote[0].instrument.tenor, quote[0].instrument.sym)\n",
    "print(pc.extra['GBP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
